{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm_model.ipynb","provenance":[{"file_id":"1UQt8sZxG5_Qlnft28OG3htNrGOYj7Z4a","timestamp":1607367173838}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"HIe_k81Z-4Hx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803087072,"user_tz":420,"elapsed":1341,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"79c59112-c3e6-48f9-f5a3-ff8f6d0fb13c"},"source":["#run if using colab\n","#uninstall if problem during bert tokenization then reinstall below\n","!pip uninstall bert-for-tf2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[33mWARNING: Skipping bert-for-tf2 as it is not installed.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XtCJNCo-dFXn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803109871,"user_tz":420,"elapsed":21145,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"c673751d-ed86-45d2-8842-1830a437cffd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CUj3of3JE5ua","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803118042,"user_tz":420,"elapsed":6404,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"4d03d5bd-08fb-4043-8ea1-8487296f649c"},"source":["!pip install bert-for-tf2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/d3/820ccaf55f1e24b5dd43583ac0da6d86c2d27bbdfffadbba69bafe73ca93/bert-for-tf2-0.14.7.tar.gz (41kB)\n","\r\u001b[K     |████████                        | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 28.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.7-cp36-none-any.whl size=30537 sha256=6f4d87b6cf3a61548ffe4890d279bd76148f06fc730cb398615526b74317bacd\n","  Stored in directory: /root/.cache/pip/wheels/e1/f8/e2/b98f79a6b8cc898d8e4102b83acb8a098df7d27500a2bac912\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=bc2c9461ca0f1ae2a7ec6c8f6131b51ca734bbda13d1614c4aa51c366f042d31\n","  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=e8f5e8b1d9ee8fe30834a079cb6d7ca1d8059d6c5ee17df321ca781498b5d808\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.7 params-flow-0.8.2 py-params-0.9.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0_Uqg5HN_LUM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803120723,"user_tz":420,"elapsed":6166,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"bbbc79fb-9f27-43c8-8acf-86dc299376b8"},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 16.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 13.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.0MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.94\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8E0wwjuJ9Rwr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803124012,"user_tz":420,"elapsed":7549,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"51c27725-cc03-4f12-d7ff-974d429663af"},"source":["!pip install emoji --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n","\r\u001b[K     |██████▍                         | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49715 sha256=585022aba7adf2b93008d2efb3a1a4a0eee7fe96f21e56471d90f98ccb6a6c31\n","  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-0.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"No_VGWsT9YZx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803124313,"user_tz":420,"elapsed":4569,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"b7f8e63a-b767-4580-d09a-3c16fa9a896f"},"source":["#cd to folder which contain required external files, TEXT_MODEL.py and text_preprocessing.py\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/cs410/CourseProject "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/cs410/CourseProject\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JTVQh4lf6VTe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607803128530,"user_tz":420,"elapsed":4212,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"b55a762d-be77-4e8f-84fd-ac43675d4959"},"source":["import tensorflow as tf \n","import tensorflow_hub as hub \n","from tensorflow.keras import layers\n","import bert\n","import numpy as np \n","import pandas as pd \n","import json\n","import re\n","import random\n","import math\n","#from TEXT_MODEL import TEXT_MODEL\n","from TEXT_PREPROCESSING import preprocess_text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKLcMTfG-fZd","executionInfo":{"status":"ok","timestamp":1607803129409,"user_tz":420,"elapsed":3538,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"856fb0ec-ece4-495a-f904-e764bcfbe237"},"source":["\n","# LOADING DATA\n","categorized_tweets = pd.read_json('./data/train.jsonl', lines = True)\n","categorized_tweets.isnull().values.any()\n","print(categorized_tweets)\n","\n","# PREPROCESSING DATA\n","tweets = []\n","data = list(categorized_tweets[\"response\"])\n","print(data[0])\n","for d in data:\n","    tweets.append(preprocess_text(d))\n","\n","y = categorized_tweets[\"label\"]\n","y = np.array(list(map(lambda x: 1 if x==\"SARCASM\" else 0, y)))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["            label  ...                                            context\n","0         SARCASM  ...  [A minor child deserves privacy and should be ...\n","1         SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n","2         SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n","3         SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n","4         SARCASM  ...  [Man ... y ’ all gone “ both sides ” the apoca...\n","...           ...  ...                                                ...\n","4995  NOT_SARCASM  ...  [@USER Apologies for the inconvenience you fac...\n","4996  NOT_SARCASM  ...  [@USER 🤔 idk tho , I think I ’ m #hungry . But...\n","4997  NOT_SARCASM  ...  [@USER @USER @USER Peace to you , and two coun...\n","4998  NOT_SARCASM  ...  [Bernie Sanders told Elizabeth Warren in priva...\n","4999  NOT_SARCASM  ...  [PDP PROTEST BRAINSTORMING SESSION Deji : We n...\n","\n","[5000 rows x 3 columns]\n","@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmdV7Bl8HaY9","executionInfo":{"status":"ok","timestamp":1607803257868,"user_tz":420,"elapsed":126523,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"b416917b-68fa-4c99-9b16-409df5c98b3f"},"source":["# TOKENIZING DATA\n","\n","BertTokenizer = bert.bert_tokenization.FullTokenizer\n","\n","bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=False)\n","vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n","\n","def tokenize_tweets(data):\n","    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(data))\n","  ##vectorized tweet\n","tokenized_tweets = [tokenize_tweets(tweet) for tweet in tweets]  \n","\n","# tokenized example\n","print(tweets[9])\n","print(tokenizer.tokenize(tweets[9]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@USER @USER @USER responds to facts by tossing out frantic insults , then accuses others of being \" triggered by facts \" 🤣 😂 🤣\n","['@', 'user', '@', 'user', '@', 'user', 'responds', 'to', 'facts', 'by', 'tossing', 'out', 'frantic', 'insults', ',', 'then', 'accuse', '##s', 'others', 'of', 'being', '\"', 'triggered', 'by', 'facts', '\"', '[UNK]', '[UNK]', '[UNK]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZG8FUEA6kFr","executionInfo":{"status":"ok","timestamp":1607803257869,"user_tz":420,"elapsed":120316,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"ae3c4de4-4822-48ff-f833-8664c97e1a9a"},"source":["#find the longest tweet in order to pad shorter tweets w zeros\n","maxlength = 0\n","for alist in tokenized_tweets:\n","    if len(alist) > maxlength:\n","        maxlength = len(alist)\n","        \n","maxlength   "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["90"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CseeOudC9mon","executionInfo":{"status":"ok","timestamp":1607803257871,"user_tz":420,"elapsed":118085,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"1e0d20bf-d9f9-43e4-b9ab-6ecabab77d02"},"source":["#pad the input vector, tweets, so all observations have the same length\n","from keras.preprocessing.sequence import pad_sequences\n","tokenized_tweets_padded = pad_sequences(tokenized_tweets, maxlen=maxlength, padding = 'post')\n","tokenized_tweets_padded[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1030,  5310,  1030,  5310,  1030,  5310,  1045,  2123,  1005,\n","        1056,  2131,  2023,  1012,  1012,  5525,  2017,  2079,  2729,\n","        2030,  2017,  2052,  1005,  2310,  2333,  2157,  2247,  1012,\n","        1012,  2612,  2017,  2787,  2000,  2729,  1998, 18792,  2014,\n","        1012,  1012,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"armOGe1e-hiB","executionInfo":{"status":"ok","timestamp":1607803257871,"user_tz":420,"elapsed":115214,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"1f6a0fb7-ab61-48ad-cefc-87db41ba5ae9"},"source":["type(tokenized_tweets_padded)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGrPcsEcHo1J","executionInfo":{"status":"ok","timestamp":1607803257872,"user_tz":420,"elapsed":113450,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"e142f4b9-afd5-48ee-cc2a-28aaaf024694"},"source":["df_x = pd.DataFrame(tokenized_tweets_padded)\n","df_x.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 90)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"nOjcaVE9KCt1","executionInfo":{"status":"ok","timestamp":1607803258078,"user_tz":420,"elapsed":112274,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"901745ed-3808-4a69-db08-f44a5ecf89d0"},"source":["df_x.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1045</td>\n","      <td>2123</td>\n","      <td>1005</td>\n","      <td>1056</td>\n","      <td>2131</td>\n","      <td>2023</td>\n","      <td>1012</td>\n","      <td>1012</td>\n","      <td>5525</td>\n","      <td>2017</td>\n","      <td>2079</td>\n","      <td>2729</td>\n","      <td>2030</td>\n","      <td>2017</td>\n","      <td>2052</td>\n","      <td>1005</td>\n","      <td>2310</td>\n","      <td>2333</td>\n","      <td>2157</td>\n","      <td>2247</td>\n","      <td>1012</td>\n","      <td>1012</td>\n","      <td>2612</td>\n","      <td>2017</td>\n","      <td>2787</td>\n","      <td>2000</td>\n","      <td>2729</td>\n","      <td>1998</td>\n","      <td>18792</td>\n","      <td>2014</td>\n","      <td>1012</td>\n","      <td>1012</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>2667</td>\n","      <td>2000</td>\n","      <td>6186</td>\n","      <td>2055</td>\n","      <td>1012</td>\n","      <td>3331</td>\n","      <td>2055</td>\n","      <td>2032</td>\n","      <td>1998</td>\n","      <td>2010</td>\n","      <td>10873</td>\n","      <td>1998</td>\n","      <td>2027</td>\n","      <td>3830</td>\n","      <td>3209</td>\n","      <td>1059</td>\n","      <td>24475</td>\n","      <td>2515</td>\n","      <td>2008</td>\n","      <td>2191</td>\n","      <td>7861</td>\n","      <td>1029</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>2002</td>\n","      <td>3084</td>\n","      <td>2019</td>\n","      <td>9577</td>\n","      <td>2055</td>\n","      <td>1997</td>\n","      <td>2769</td>\n","      <td>2013</td>\n","      <td>1996</td>\n","      <td>5691</td>\n","      <td>1010</td>\n","      <td>15313</td>\n","      <td>999</td>\n","      <td>1001</td>\n","      <td>4553</td>\n","      <td>14406</td>\n","      <td>24138</td>\n","      <td>27268</td>\n","      <td>6633</td>\n","      <td>9316</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>5564</td>\n","      <td>8398</td>\n","      <td>2180</td>\n","      <td>1005</td>\n","      <td>1056</td>\n","      <td>2130</td>\n","      <td>2713</td>\n","      <td>2010</td>\n","      <td>2938</td>\n","      <td>7644</td>\n","      <td>1998</td>\n","      <td>2010</td>\n","      <td>24249</td>\n","      <td>12655</td>\n","      <td>2056</td>\n","      <td>2002</td>\n","      <td>2001</td>\n","      <td>1996</td>\n","      <td>12873</td>\n","      <td>4355</td>\n","      <td>3076</td>\n","      <td>2027</td>\n","      <td>1005</td>\n","      <td>2310</td>\n","      <td>2412</td>\n","      <td>4036</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>3492</td>\n","      <td>2469</td>\n","      <td>1996</td>\n","      <td>3424</td>\n","      <td>1011</td>\n","      <td>5367</td>\n","      <td>4306</td>\n","      <td>3555</td>\n","      <td>2008</td>\n","      <td>1000</td>\n","      <td>7072</td>\n","      <td>2001</td>\n","      <td>2006</td>\n","      <td>1996</td>\n","      <td>10428</td>\n","      <td>1000</td>\n","      <td>1999</td>\n","      <td>7313</td>\n","      <td>1010</td>\n","      <td>2205</td>\n","      <td>1012</td>\n","      <td>2027</td>\n","      <td>2245</td>\n","      <td>5367</td>\n","      <td>2001</td>\n","      <td>1000</td>\n","      <td>27246</td>\n","      <td>1000</td>\n","      <td>1012</td>\n","      <td>1001</td>\n","      <td>2175</td>\n","      <td>2361</td>\n","      <td>1001</td>\n","      <td>2283</td>\n","      <td>11253</td>\n","      <td>4115</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 90 columns</p>\n","</div>"],"text/plain":["     0     1     2     3     4     5     6   ...  83  84  85  86  87  88  89\n","0  1030  5310  1030  5310  1030  5310  1045  ...   0   0   0   0   0   0   0\n","1  1030  5310  1030  5310  2667  2000  6186  ...   0   0   0   0   0   0   0\n","2  1030  5310  1030  5310  1030  5310  2002  ...   0   0   0   0   0   0   0\n","3  1030  5310  1030  5310  5564  8398  2180  ...   0   0   0   0   0   0   0\n","4  1030  5310  1030  5310  3492  2469  1996  ...   0   0   0   0   0   0   0\n","\n","[5 rows x 90 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GynlXdJipn-_","executionInfo":{"status":"ok","timestamp":1607803258080,"user_tz":420,"elapsed":110572,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"dff3f2fe-e003-4d7d-c5a8-b3ba722b727f"},"source":["print(len(tokenizer.vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30522\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5baGx3DLzBwy"},"source":["#randomize and split into test and train datasets X,y\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df_x, y, test_size = 0.20, shuffle = True, random_state = 33)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBcTD8EE1DKV","executionInfo":{"status":"ok","timestamp":1607803258698,"user_tz":420,"elapsed":602,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"ae7c88e1-7856-481d-9971-60999cf79b8e"},"source":["X_train.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4000, 90)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7p_U7teCfbB","executionInfo":{"status":"ok","timestamp":1607803259056,"user_tz":420,"elapsed":945,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"f7a71869-ca89-4837-b2af-8b39385b5af0"},"source":["from keras.layers import LSTM\n","\n","input_length = X_train.shape[1]\n","VOCAB_LENGTH = len(tokenizer.vocab)\n","EMB_DIM = 200\n","\n","model = tf.keras.Sequential()\n","model.add(layers.Embedding(VOCAB_LENGTH, EMB_DIM, input_length=input_length))\n","model.add(LSTM(units=64, activation='tanh' ))\n","\n","model.add(layers.Flatten())\n","\n","#model.add(layers.Dense(128, activation='relu'))\n","\n","\n","\n","\n","#model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(64))\n","model.add(layers.Dropout(rate= 0.5))\n","model.add(layers.Activation('relu'))\n","\n","\n","#model.add(layers.Dense(28, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","print(model.summary())\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 90, 200)           6104400   \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 64)                67840     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 64)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                4160      \n","_________________________________________________________________\n","dropout (Dropout)            (None, 64)                0         \n","_________________________________________________________________\n","activation (Activation)      (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 6,176,465\n","Trainable params: 6,176,465\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N2ThGPTrxGb8"},"source":["#AdamW not working???\n","from tensorflow_addons.optimizers import AdamW\n","import tensorflow_addons as tfa\n","step = tf.Variable(0, trainable=False)\n","schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n","    [10000, 15000], [1e-0, 1e-1, 1e-2])\n","# lr and wd can be a function or a tensor\n","lr = 1e-1 * schedule(step)\n","wd = lambda: 1e-4 * schedule(step)\n","\n","# ...\n","\n","optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYlvykgS3vcG","executionInfo":{"status":"ok","timestamp":1607803607882,"user_tz":420,"elapsed":253826,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"b08f8f28-3902-4aca-9031-cb12f0c2432f"},"source":["# compile network\n","from tensorflow.keras import optimizers\n","\n","opt = optimizers.Adam(learning_rate=.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(loss='binary_crossentropy', optimizer= opt, metrics=['accuracy'])\n","# fit network\n","model.fit(X_train, y_train, batch_size = 32, validation_data = (X_test, y_test), epochs=30, verbose=1)\n","# evaluate\n","loss, acc = model.evaluate(X_test, y_test, verbose=1)\n","print('Test Accuracy: %f' % (acc*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","125/125 [==============================] - 9s 71ms/step - loss: 0.6936 - accuracy: 0.4972 - val_loss: 0.6936 - val_accuracy: 0.4950\n","Epoch 2/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6937 - accuracy: 0.5017 - val_loss: 0.6930 - val_accuracy: 0.5140\n","Epoch 3/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6913 - accuracy: 0.5238 - val_loss: 0.6790 - val_accuracy: 0.6030\n","Epoch 4/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6193 - accuracy: 0.6890 - val_loss: 0.5827 - val_accuracy: 0.7260\n","Epoch 5/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.5516 - accuracy: 0.7667 - val_loss: 0.5909 - val_accuracy: 0.7170\n","Epoch 6/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.4947 - accuracy: 0.8062 - val_loss: 0.6495 - val_accuracy: 0.7270\n","Epoch 7/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.4631 - accuracy: 0.8263 - val_loss: 0.5910 - val_accuracy: 0.7410\n","Epoch 8/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.4731 - accuracy: 0.8190 - val_loss: 0.5882 - val_accuracy: 0.7370\n","Epoch 9/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6956 - accuracy: 0.5295 - val_loss: 0.6932 - val_accuracy: 0.4950\n","Epoch 10/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6935 - accuracy: 0.5077 - val_loss: 0.6930 - val_accuracy: 0.4950\n","Epoch 11/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6925 - accuracy: 0.5123 - val_loss: 0.6928 - val_accuracy: 0.4950\n","Epoch 12/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6922 - accuracy: 0.4947 - val_loss: 0.6913 - val_accuracy: 0.5380\n","Epoch 13/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6689 - accuracy: 0.5525 - val_loss: 0.6094 - val_accuracy: 0.7250\n","Epoch 14/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.4864 - accuracy: 0.8002 - val_loss: 0.6958 - val_accuracy: 0.7210\n","Epoch 15/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.4733 - accuracy: 0.7972 - val_loss: 0.6805 - val_accuracy: 0.7250\n","Epoch 16/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.4862 - accuracy: 0.8077 - val_loss: 0.6435 - val_accuracy: 0.7160\n","Epoch 17/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.4946 - accuracy: 0.8083 - val_loss: 0.6297 - val_accuracy: 0.6970\n","Epoch 18/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.4962 - accuracy: 0.8098 - val_loss: 0.6242 - val_accuracy: 0.7230\n","Epoch 19/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6006 - accuracy: 0.6503 - val_loss: 0.6950 - val_accuracy: 0.5210\n","Epoch 20/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6765 - accuracy: 0.5265 - val_loss: 0.6955 - val_accuracy: 0.5210\n","Epoch 21/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6762 - accuracy: 0.5310 - val_loss: 0.6919 - val_accuracy: 0.5210\n","Epoch 22/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6725 - accuracy: 0.5387 - val_loss: 0.7007 - val_accuracy: 0.5210\n","Epoch 23/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6737 - accuracy: 0.5253 - val_loss: 0.6997 - val_accuracy: 0.5210\n","Epoch 24/30\n","125/125 [==============================] - 8s 68ms/step - loss: 0.6723 - accuracy: 0.5300 - val_loss: 0.7013 - val_accuracy: 0.5210\n","Epoch 25/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6728 - accuracy: 0.5357 - val_loss: 0.6978 - val_accuracy: 0.5210\n","Epoch 26/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6711 - accuracy: 0.5385 - val_loss: 0.7018 - val_accuracy: 0.5210\n","Epoch 27/30\n","125/125 [==============================] - 8s 67ms/step - loss: 0.6709 - accuracy: 0.5383 - val_loss: 0.7035 - val_accuracy: 0.5210\n","Epoch 28/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6705 - accuracy: 0.5397 - val_loss: 0.7029 - val_accuracy: 0.5210\n","Epoch 29/30\n","125/125 [==============================] - 8s 66ms/step - loss: 0.6715 - accuracy: 0.5362 - val_loss: 0.7026 - val_accuracy: 0.5210\n","Epoch 30/30\n","125/125 [==============================] - 8s 68ms/step - loss: 0.6710 - accuracy: 0.5397 - val_loss: 0.6998 - val_accuracy: 0.5210\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.5210\n","Test Accuracy: 52.100003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XN_GWhmKmJJk","executionInfo":{"status":"ok","timestamp":1607374794020,"user_tz":420,"elapsed":328,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"d1d17ca4-868a-4feb-8538-be56f8ec3389"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","y_prediction = model.predict(X_test)\n","y_pred = []\n","for i in y_prediction:\n","    if i >= 0.5:\n","        y_pred.append(1)\n","    else:\n","        y_pred.append(0)    \n","\n","\n","p,r,f,n = precision_recall_fscore_support(y_test, y_pred, average='macro')\n","print('p = ',p, ', r = ', r, ', f = ', f)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["p =  0.7811278749439426 , r =  0.7808680868086808 , f =  0.78090337838987\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5j4plTpzG4D-"},"source":["#use if you want to save the model\n","#model.save(\"/content/drive/My Drive/Colab Notebooks/cs410/network02c\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPTTFKmaKaHF"},"source":["# Predict using model\n","uncat_tweets = pd.read_json('./data/test.jsonl', lines = True)\n","un_tweets = []\n","uncat_data = list(uncat_tweets[\"response\"])\n","\n","for d in uncat_data:\n","    un_tweets.append(preprocess_text(d))\n","tokenized_un_tweets = [tokenize_tweets(tweet) for tweet in un_tweets]\n","print(str(len(un_tweets)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nzn4OdoKqUF"},"source":["#perform check of input lengths between test and train data\n","count = 0\n","for alist in tokenized_un_tweets:\n","    if len(alist) > count:\n","        count = len(alist)\n","if maxlength < count:\n","    print('error: input of test data input len greater than train data- need to fix')\n","else:\n","    print(\"ok to proceed\")    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWV_o9lTMyPQ"},"source":["tokenized_untweets_padded = pad_sequences(tokenized_un_tweets, maxlen=maxlength, padding = 'post')\n","tokenized_untweets_padded[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YC3SQVl96CLv"},"source":["\n","\n","predictions = model.predict(tokenized_untweets_padded)\n","\n","with open('answer.txt', 'w') as f:\n","    c = 1\n","    s_c = 0\n","    ns_c = 0\n","    for p in predictions:\n","        if p >= .5:\n","            f.write(\"twitter_\" + str(c) + \",\" + \"SARCASM\\n\")\n","            c += 1\n","            s_c += 1\n","        else:\n","            f.write(\"twitter_\" + str(c) + \",\" + \"NOT_SARCASM\\n\")\n","            c += 1\n","            ns_c += 1\n","print(\"# sarcasm: \" + str(s_c))\n","print(\"# not sarcasm: \" + str(ns_c))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMK33wP_OnQ_"},"source":["!git commit -m \"network_04a\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpKpm0qCsVqz"},"source":[""],"execution_count":null,"outputs":[]}]}